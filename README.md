# Contemporary Issues In Data

Welcome! Your writing assignment will be in this file.  See [the instructions](./instructions.md) for more details.

# Apple’s Illusion of Privacy Is Getting Harder to Sell
I'll be discussing the Apple's privacy and safety systems to avoid child sexual abuse materials.

## Article 1
After the backlash against Apple's new technology to scan pictures to look for child sexual abuse materials (CSAM), Apple users are concerned with their own data privacy. In New York Times' article [Apple’s Illusion of Privacy Is Getting Harder to Sell](https://www.nytimes.com/2021/08/19/opinion/apple-iphone-privacy.html?searchResultPosition=9), the author Greg Bensinger argues that "our data is as secure as their policies". What he means is Apple may advertise that privacy is their #1 priority, but when it comes to changing their policy to reaching out to new costumers in new countries, they would forget about what really matters. Apple's new technolgy and policy of scanning the users' pictures was first advertised as a way to ensure protection against CSAM, but their actions proved differently. For instance, Apple has made Chinese users’ data accessible to the Chinese government, which goes completely against their "What happens on your iPhone stays on your iPhone" advertisement. 

I believe that this article reflects on the suspicion that users are getting from tech companies, not just Apple. They tend to advertise something great, safe and useful which is very attracting at first. However, new scandals and controversies are discovered everyday, which makes people become more and more afraid of getting new services. The best way to fix that would be if companies were more transparent from the beggining, so then their users could start trusting more in their policies from the beggining. 



## Article 2
In Wired's article [How Apple can fix its child sexual abuse problem](https://www.wired.co.uk/article/apple-photo-scanning-csam), the author Matt Burgess argues that the new scanning technology is a good way to prevent CSAM. Although this article also punctuates the flaws in Apple's policies, and how this new technology would allow governments to search the population's phones looking for other material. The article also mentions Matthew Green, a cryptographer from Johns Hopkins, that argues that Apple should talk with policy and technical experts, but also include the public in the conversation.

I think this article has a good point, better than the previous one. I understand that sharing users' data is something that should not happen (especially without their consent). However, CSAM is a problem and this is a solution for now. Until there are better technologies and policies that could end it, this what can be done for now. Besides, I agree with what Matthew Green says, because it is really important for Apple to listen to their costumers for once. I am sure all users are as concerned with CSAM as the company, so working together to find a solution is essential.